I was able to pretty easily recognize this problem as being 'write a cardinality function for strict partitions (but excluding the strict partition with one part). Or OEIS sequence A000009 ( https://oeis.org/A000009 ), but minus 1. I've done a lot of work with similar types of things (in particular, symmetric plane partitions). I wasted a lot of time on this because I originally wanted to write an iterator to generate all strict partitions, and got bogged down in remembering exactly how to make yield statements do what I wanted. But total enumeration is too slow of a cardinality method for the cases they wanted you to be able to handle, so I had to switch to a recurrence relation

The rough idea is that f(boxes_left,largest_part) returns the number of strict partitions of 'boxes_left', where the first entry must be less than 'largest_part'. We recursively run this for all possible ways of adding a next row of boxes, initialized with having n boxes left and largest part must be less than n (this will exclude the singleton partition). However, if we do this as a straight recursion, we are effectively still just iterating over all possible strict partitions, we just aren't constructing the actual partition along the way.

The thing that's necessary to speed this up is an auxilliary list that keeps track of values f(boxes_left,largest_part) we've already computed instead of repeating the recursive procedure each time that function is called. In my submitted solution, I did this somewhat clunkily with a global list that I made large enough for the bounds given in the problem, but keeping a running dictionary is much more efficient, and is done in the solution presented here.

Edit (July 2020): 

Upon further review, this is 100% supposed to be a dynamic programming problem, and it seems I managed to come up with the top-down/memoized version (hooray for reading a book and learning terminology for things you've apparently already been doing). I decided to try and do the bottom-up/dynamic programming approach to see if there's any performance improvement. 

After spending a lot of time thinking trying to make bottom-up performance get close to the top-down approach and worrying I just wasn't being clever enough in terms of avoiding extraneous sub-problems, I've managed to convince myself that this is just fundamentally a problem better suited to top-down in order to avoid extraneous sub-problems. 

A more typical application of dynamic programming would be something where you want to compute f(n,n), and you have a way to compute f(i,j) in terms of localized entries (f(i-1,j), f(i,j-1), etc.). In that case, you would likely need to solve every sub-problem f(i,j) for 1\leq i,j \leq n , and performance between bottom-up should be comparable to top-down (and I've been told typically better by a constant factor due to less overhead and caching and "reasons"). A nice side effect of me using a dictionary instead of an array for tracking values was that it made it easy to see how many "sub-problems" I was solving, instead of having sub-problems never reached and sub-problems reached with zero solutions looking identical. Bottom-up approach was using about n^2/2 sub-problems (if you set up things the right way, you can potentially limit yourself to i/geq j), but top-down was only using about half as many sub-problems. 

And I've come to realize that that's just a fundamental thing about this problem, where your recursive step is computing f(i,j) in terms of f(i-k,k) k<j for terms much lower in the array, instead of always going up/to the left by a single step.
